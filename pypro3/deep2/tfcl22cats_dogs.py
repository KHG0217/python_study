# -*- coding: utf-8 -*-
"""tfcl22cats_dogs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19WuSMGM6ePt7Iv1_1ZmNKwRH62rQonCO
"""

# CNN을 사용하여 개/고양이 이미지(고차원) 분류 모델 작성
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
import numpy as np
import matplotlib.pyplot as plt

# 데이터 다운로드
data_url ='https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=data_url, extract=True)
PATH = os.path.join(os.path.dirname(path_to_zip),'cats_and_dogs_filtered' )

!find / -name 'cats_and_dogs*'
!ls /root/.keras/datasets/cats_and_dogs_filtered/train/cats/ -la

batch_size = 128
epochs = 15
IMG_HEIGHT = 150
IMG_WIDTH = 150

# 이미지 준비
train_dir = os.path.join(PATH, 'train')

print(train_dir)

validation_dir = os.path.join(PATH, 'validation')

train_cats_dir = os.path.join(train_dir, 'cats')
# print(train_cats_dir)
train_dogs_dir = os.path.join(train_dir, 'dogs')

validation_cats_dir = os.path.join(validation_dir, 'cats')
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

# # 이미지 확인
num_cats_tr = len(os.listdir(train_cats_dir))
num_dogs_tr = len(os.listdir(train_dogs_dir))
print(os.listdir(train_cats_dir)[:5])

num_cats_val = len(os.listdir(validation_cats_dir))
num_dogs_val = len(os.listdir(validation_dogs_dir))

total_train = num_cats_tr + num_dogs_tr
total_val = num_cats_val + num_dogs_val




print('total train cat images : ',num_cats_tr )
print('total train dog images : ',num_dogs_tr )

print('total train cat images : ',num_cats_val )
print('total train dog images : ',num_dogs_val )
print('----')

print('total train images : ',total_train)
print('total val images : ',total_val)

# 하드디스크에 저장된 이미지를 메모리로 로딩 (행렬값을 변수에 담기)
# 데이터를 RGB 이미지 형태에 맞게 디코딩 후 실수 텐서로 변환
# 정규화
# imageDataGenerator를 이용함
train_image_generator = ImageDataGenerator(rescale=1. / 255)
validation_image_generator = ImageDataGenerator(rescale=1. / 255)

train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           target_size=(IMG_HEIGHT,IMG_WIDTH),
                                                           class_mode='binary') # (128,150,150,3)

val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=validation_dir,
                                                           target_size=(IMG_HEIGHT,IMG_WIDTH),
                                                           class_mode='binary') # (128,150,150,3)

for a, b in train_data_gen:
  print(a.shape) # a 이미지
  print(b.shape) # b 라벨
  print(b[0])
  print(b[1])
  break


# 로딩된 데이터 확인 : next() 사용
sample_training_images, _ = next(train_data_gen) # iterator 반환

def plotImage(img_arr):
  fig, axes = plt.subplots(1, 5, figsize=(20, 20))
  axes = axes.flatten()
  for img, ax in zip(img_arr,axes):
    ax.imshow(img)
    ax.axis('off')
  plt.tight_layout()
  plt.show()
  

plotImage(sample_training_images[:5])
print(sample_training_images[:1])

# model
model = Sequential([
    Conv2D(filters=16, kernel_size=3, padding='same',activation='relu' ,input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(pool_size=2),
    Conv2D(filters=32, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size=2),
    Conv2D(filters=64, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size=2),
    Flatten(),
    Dense(units=512,activation='relu'),
    Dense(1)

])
model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])
print(model.summary())

history = model.fit_generator(train_data_gen,
                              steps_per_epoch=total_train // batch_size,
                              epochs=epochs,
                              validation_data = val_data_gen, 
                              validation_steps=total_val // batch_size)
#하나의 에포글 처리하고, 다음 에폭을 시작하기까지 재너레이커에서 생성할 단계(샘플배치)의 총갯수를 배치크기로 나눔

model.save('cat_god.h5')

# 시각화
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(1, epochs + 1)

plt.figure(figsize=(8, 8))
plt.subplot(1,2,1)
plt.plot(epochs_range, acc, label='train acc')
plt.plot(epochs_range, val_acc, label='val acc')
plt.legend(loc='best')
plt.show()

plt.subplot(1,2,2)
plt.plot(epochs_range, loss, label='train loss')
plt.plot(epochs_range, val_loss, label='val loss')
plt.legend(loc='best')
plt.show()

# 과적합이 발생. 원인은 매우 다양.
# 데이터 수가 적은 것도 원인일 수 있다. - 이미지 보강으로 해결
image_gen_train = ImageDataGenerator(
    rescale = 1./255,
    rotation_range = 45,
    width_shift_range = 0.15,
    height_shift_range = 0.15,
    horizontal_flip = True,
    zoom_range = 0.5
)
train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir, shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')  # (128,150,150,3)
augumented_images = [train_data_gen[0][0][0] for i in range(5)]
plotImage(augumented_images)

# 이미지 보강은 주로 train에 대해서만 진행. validation은 잘하지 않음
image_gen_val = ImageDataGenerator(
    rescale = 1./255
)

val_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir, shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')  # (128,150,150,3)



# model
model_new = Sequential([
    Conv2D(filters=16, kernel_size=3, padding='same',activation='relu' ,input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D(pool_size=2),
    Dropout(rate=0.2),
    Conv2D(filters=32, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size=2),
    Dropout(rate=0.2),
    Conv2D(filters=64, kernel_size=3, padding='same',activation='relu'),
    MaxPooling2D(pool_size=2),
    Dropout(rate=0.2),
    Flatten(),
    Dense(units=512,activation='relu'),
    Dense(1)

])
model_new.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])
print(model.summary())

history = model_new.fit_generator(train_data_gen,
                              steps_per_epoch=total_train // batch_size,
                              epochs=epochs,
                              validation_data = val_data_gen, 
                              validation_steps=total_val // batch_size)
#하나의 에포글 처리하고, 다음 에폭을 시작하기까지 재너레이커에서 생성할 단계(샘플배치)의 총갯수를 배치크기로 나눔

# 시각화
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(1, epochs + 1)

plt.figure(figsize=(8, 8))
plt.subplot(1,2,1)
plt.plot(epochs_range, acc, label='train acc')
plt.plot(epochs_range, val_acc, label='val acc')
plt.legend(loc='best')
plt.show()

plt.subplot(1,2,2)
plt.plot(epochs_range, loss, label='train loss')
plt.plot(epochs_range, val_loss, label='val loss')
plt.legend(loc='best')
plt.show()

# 새로운 이미지로 분류
from google.colab import files
from keras.preprocessing import image

uploaded = files.upload()

for fn in uploaded.keys():
  path = '/content/' + fn
  img = image.load_img(path, target_size=(150, 150))

  x= image.img_to_array(img)
  # print(x)

  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model_new.predict(images, batch_size=10)
  print(classes)
  print(classes[0])

if classes[0] >0:
  print(fn + "는 댕댕이")
else:
  print(fn + "는 냥이")