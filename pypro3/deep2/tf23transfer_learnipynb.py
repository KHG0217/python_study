# -*- coding: utf-8 -*-
"""tf23transfer_learnipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNrfRR1A1n23ZNA4r07YAphl1GcE3uay
"""

# Transfer Learning(전이학습) : 미리 학습된 모델과 파라미터를 불러다 그대로 사용할 수 있으나, 레이어의 일부를 수정해
# 내가 원하는 모양의 모델을 만들 수 있다.
# 방법 1 : 특성 추출 기법 - 사전 훈련된 모델의 마지막 완전 연결층 부분만 새로 작성
# 방법 2 : 미세조정 기법

# 방법 1 : 특정 추출 기법
# 데이터 파악 -> 입력데이터 파이프라인 작성 -> 모델 작성 -> 모델 학습 ->검증
# 미리 학습된 모델을 구글에서 개발 MobileNetV2를 사용하겠다.

# pip install tensorflow-datasets
!pip install tensorflow-datasets

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow_datasets as tfds

tfds.disable_progress_bar()

(raw_train, raw_validation, raw_test), metadata = tfds.load('cats_vs_dogs',
                                                  split=['train[:80%]', 'train[80%:90%]','train[90%:]'],
                                                  with_info=True, as_supervised=True)

print(raw_train)
print(raw_train.take(1))
print(raw_validation)
print(raw_test)
print(metadata)

get_label_name = metadata.features['label'].int2str
print(get_label_name)

for image, label in raw_train.take(5):
  plt.figure()
  plt.imshow(image)
  plt.title(get_vabel_name(label))
  plt.show()

  # 대용량의 이미지를 하드에서 주기억장치로 여러장을 읽는다면 시스템의 성능이 저하됨
  # 현재 메모리 용량에 맞춰서 이미지를 로딩하고, 사용이 끝난 이미지를 제거하는 일련의 작업을 데이터 파이프라인을 이용해서 할 수있다.
  # https://m.blog.naver.com/euue717/222086046496 참조

# 이미지 포맷팅, 셔플링 예정이다 => MobileNetV2가 원하니까
IMG_SIZE = 160

def format_example(image, label):
  image = tf.cast(image, tf.float32)
  image = (image / 127.5) - 1
  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  return image, label

train = raw_train.map(format_example)
validation = raw_validation.map(format_example)
test = raw_test.map(format_example)

BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE) # train만 셔플링 (섞어주기)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)

for image_batch, label_batch in train_batches.take(1):
  pass

print(image_batch.shape) # (32, 160, 160, 3)
print(label_batch.shape) # 32,)

# 베이스 모델 생성 : MobileNetV2 - 많은 데이터로 충분히 학습한 이미지 분류 모델
IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)

base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, 
                                               include_top=False,
                                               weights = 'imagenet')
# include_top=False : 완전 연결층을 포함여부 결정(입력층) -> (CNN 계층) -> 특징추출
# include_top=False: 완전 연결층 포험을 안하겠다.

# 계층 동결
base_model.trainable = False
print(base_model.summary())

# 분류 모델링 : 전이학습을 사용하여 원하는 이미지 분류기를 생성
# 추출된 특징들을 이용하여 Dense 계층(완전연결층)으로 이어져야 한다.
# base_model이 최종적으로 출력한 특징은 (None, 5, 5, 1280)임
# 이 것을 완전연결층에 맞도록 차원을 줄여주기 위한 벡터화 작업을 진행해야 함.